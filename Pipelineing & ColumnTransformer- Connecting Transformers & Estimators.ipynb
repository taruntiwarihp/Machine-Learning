{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "* Pipeline (software) ... In software engineering, a pipeline consists of a chain of processing elements (processes, threads, coroutines, functions, etc.), arranged so that the output of each element is the input of the next; the name is by analogy to a physical pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives\n",
    "* Challenges with current code\n",
    "* Understanding pipeline\n",
    "* Solving Problems using Pipeline\n",
    "* Challenges with pipeline\n",
    "* Solving hetrogenous data problem with ColumnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenges with current code\n",
    "* Dev have to do manually the preprocessing followed by putting the data in the estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits #import dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, testX, trainY, testY = train_test_split(digits.data, digits.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX_tf = ss.fit_transform(trainX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(trainX_tf, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is incorrect, test isn't transformed\n",
    "#rf.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX_tf = ss.transform(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 7, 9, 9, 2, 0, 9, 8, 4, 8, 1, 9, 8, 9, 1, 8, 6, 8, 7, 3, 5,\n",
       "       5, 7, 8, 9, 6, 6, 4, 6, 7, 6, 8, 7, 9, 4, 2, 7, 8, 6, 6, 2, 9, 4,\n",
       "       0, 5, 3, 3, 3, 5, 5, 8, 7, 1, 0, 5, 6, 3, 5, 5, 8, 2, 0, 9, 7, 8,\n",
       "       6, 3, 4, 4, 6, 7, 7, 9, 7, 9, 1, 6, 7, 3, 0, 2, 8, 7, 5, 1, 5, 0,\n",
       "       0, 7, 5, 4, 0, 9, 8, 9, 5, 5, 4, 3, 2, 1, 0, 9, 1, 9, 0, 7, 4, 9,\n",
       "       6, 5, 6, 3, 0, 1, 2, 5, 6, 2, 7, 6, 9, 5, 8, 0, 0, 7, 9, 1, 3, 6,\n",
       "       2, 4, 3, 4, 0, 5, 6, 9, 6, 1, 5, 1, 1, 2, 7, 5, 3, 6, 7, 2, 1, 5,\n",
       "       4, 4, 4, 1, 7, 9, 1, 6, 2, 6, 5, 6, 7, 6, 4, 1, 8, 5, 2, 1, 2, 3,\n",
       "       6, 9, 1, 3, 4, 1, 1, 2, 4, 4, 9, 5, 3, 6, 6, 1, 4, 8, 8, 5, 8, 5,\n",
       "       2, 5, 1, 7, 1, 2, 7, 7, 6, 0, 7, 9, 7, 1, 2, 7, 9, 2, 9, 9, 9, 9,\n",
       "       9, 9, 2, 5, 1, 9, 9, 7, 4, 8, 8, 2, 9, 7, 7, 0, 1, 1, 4, 3, 3, 6,\n",
       "       0, 0, 0, 9, 2, 6, 4, 9, 7, 6, 9, 6, 5, 7, 7, 7, 9, 0, 1, 7, 6, 9,\n",
       "       8, 3, 5, 7, 2, 4, 1, 0, 5, 2, 9, 3, 3, 3, 4, 7, 1, 3, 1, 1, 3, 7,\n",
       "       5, 5, 4, 5, 1, 4, 6, 7, 1, 2, 6, 9, 4, 8, 6, 7, 3, 2, 1, 8, 7, 7,\n",
       "       9, 0, 1, 4, 0, 8, 5, 0, 2, 4, 4, 9, 5, 0, 1, 3, 9, 0, 4, 8, 4, 5,\n",
       "       2, 3, 2, 1, 6, 1, 4, 1, 6, 2, 9, 0, 5, 6, 0, 5, 2, 5, 5, 9, 1, 8,\n",
       "       0, 1, 0, 7, 0, 8, 2, 4, 5, 5, 9, 0, 0, 4, 8, 0, 6, 6, 2, 4, 3, 4,\n",
       "       3, 9, 4, 8, 0, 9, 4, 3, 4, 1, 6, 9, 1, 5, 3, 5, 9, 3, 7, 7, 5, 7,\n",
       "       3, 7, 6, 1, 2, 3, 1, 4, 5, 5, 7, 7, 9, 6, 9, 0, 0, 1, 3, 8, 9, 1,\n",
       "       7, 8, 7, 5, 4, 1, 4, 1, 2, 2, 4, 9, 6, 8, 2, 5, 3, 4, 1, 3, 8, 5,\n",
       "       5, 7, 1, 4, 5, 0, 7, 5, 5, 7])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.predict(testX_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenges\n",
    "* Different features need different preprocessing\n",
    "* It's very cumbersome to do things the current way\n",
    "* We have to preserve manually all the preprocessors used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline\n",
    "* It connectd preprocessors & estimators & thus removes the need to store them manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_pipeline = make_pipeline(StandardScaler(), RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('randomforestclassifier', RandomForestClassifier())])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit_pipeline.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 7, 9, 9, 2, 0, 9, 8, 4, 8, 1, 9, 8, 9, 1, 8, 6, 8, 7, 3, 5,\n",
       "       5, 7, 8, 9, 6, 6, 4, 6, 7, 6, 8, 7, 9, 4, 2, 7, 8, 6, 6, 2, 9, 4,\n",
       "       0, 5, 3, 3, 3, 5, 5, 8, 7, 1, 0, 5, 6, 3, 5, 5, 8, 2, 0, 9, 8, 8,\n",
       "       6, 3, 4, 4, 6, 7, 7, 9, 7, 9, 1, 6, 7, 3, 0, 2, 8, 7, 5, 1, 5, 0,\n",
       "       0, 7, 5, 4, 0, 9, 8, 9, 5, 5, 4, 3, 2, 1, 0, 9, 1, 9, 0, 7, 4, 9,\n",
       "       6, 5, 6, 3, 0, 1, 2, 5, 6, 2, 7, 6, 9, 5, 8, 0, 0, 7, 9, 1, 3, 6,\n",
       "       2, 4, 3, 4, 0, 5, 6, 9, 6, 1, 5, 1, 1, 2, 7, 5, 3, 6, 7, 2, 1, 5,\n",
       "       4, 8, 4, 1, 4, 9, 1, 6, 2, 6, 5, 6, 7, 6, 4, 1, 8, 5, 2, 1, 2, 3,\n",
       "       6, 9, 1, 3, 4, 1, 1, 2, 4, 4, 9, 5, 3, 6, 6, 1, 4, 8, 8, 5, 8, 5,\n",
       "       2, 5, 1, 7, 1, 2, 7, 7, 6, 0, 7, 9, 7, 1, 2, 7, 9, 2, 9, 9, 9, 9,\n",
       "       9, 9, 2, 5, 1, 9, 9, 7, 4, 8, 8, 2, 9, 7, 7, 4, 1, 1, 4, 3, 3, 6,\n",
       "       0, 0, 0, 9, 2, 6, 4, 9, 7, 6, 9, 6, 5, 7, 7, 7, 9, 0, 1, 7, 6, 9,\n",
       "       8, 3, 5, 7, 2, 6, 1, 0, 5, 2, 9, 3, 3, 3, 4, 7, 1, 3, 1, 1, 3, 7,\n",
       "       5, 5, 4, 5, 1, 4, 6, 7, 1, 2, 6, 9, 4, 8, 6, 7, 3, 2, 1, 8, 7, 7,\n",
       "       9, 0, 1, 4, 0, 8, 5, 0, 2, 4, 4, 9, 5, 0, 1, 3, 9, 0, 4, 8, 4, 5,\n",
       "       2, 3, 2, 1, 6, 1, 4, 1, 6, 2, 9, 0, 5, 6, 0, 5, 2, 5, 5, 9, 1, 8,\n",
       "       0, 1, 0, 7, 0, 8, 2, 4, 5, 5, 9, 0, 0, 4, 8, 0, 6, 6, 2, 4, 3, 4,\n",
       "       3, 9, 4, 3, 0, 9, 4, 5, 4, 1, 6, 9, 1, 5, 3, 5, 9, 3, 7, 7, 5, 3,\n",
       "       3, 7, 6, 1, 2, 3, 1, 4, 5, 5, 7, 7, 9, 6, 9, 0, 0, 1, 3, 8, 9, 1,\n",
       "       7, 8, 7, 5, 4, 1, 4, 1, 2, 2, 4, 9, 6, 8, 2, 5, 3, 4, 1, 3, 8, 5,\n",
       "       5, 7, 1, 4, 5, 0, 7, 5, 5, 7])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit_pipeline.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 1.74761677e-03, 2.10682705e-02, 1.08093112e-02,\n",
       "       9.76391126e-03, 1.93340730e-02, 7.67069646e-03, 8.78277772e-04,\n",
       "       5.13579234e-05, 1.09612704e-02, 2.18566631e-02, 6.60370589e-03,\n",
       "       1.45240906e-02, 2.68622565e-02, 5.37438243e-03, 5.87675187e-04,\n",
       "       9.00089499e-05, 9.05955704e-03, 1.95759053e-02, 2.67725260e-02,\n",
       "       2.64382655e-02, 4.68501371e-02, 6.78349626e-03, 5.54260537e-04,\n",
       "       9.61485486e-05, 1.17798861e-02, 4.47404592e-02, 2.58624774e-02,\n",
       "       2.94098275e-02, 2.08278264e-02, 2.97352453e-02, 4.08924413e-05,\n",
       "       0.00000000e+00, 3.37402981e-02, 2.74943920e-02, 2.17318191e-02,\n",
       "       4.37048189e-02, 2.30719486e-02, 2.46691249e-02, 0.00000000e+00,\n",
       "       4.56080916e-05, 1.15174977e-02, 3.92086174e-02, 4.59142334e-02,\n",
       "       2.13425746e-02, 2.16791479e-02, 1.99171637e-02, 1.50484159e-04,\n",
       "       0.00000000e+00, 3.04613058e-03, 1.78457224e-02, 2.43841051e-02,\n",
       "       1.29109101e-02, 2.14333911e-02, 2.47735890e-02, 1.82840595e-03,\n",
       "       0.00000000e+00, 1.89052798e-03, 2.11538444e-02, 1.02852474e-02,\n",
       "       2.12733859e-02, 2.57018158e-02, 1.83109357e-02, 4.26378168e-03])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit_pipeline.steps[1][1].feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting Pipeline with Hyper-parameter Tunning\n",
    "* We could determine the best combination of hyper-parameters for preprocessor & estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_pipeline = make_pipeline(StandardScaler(), SelectKBest(k=10, score_func=f_classif), RandomForestClassifier(n_estimators=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('selectkbest', SelectKBest()),\n",
       "                ('randomforestclassifier', RandomForestClassifier())])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {'selectkbest__k':[20,30,40],'randomforestclassifier__n_estimators':[100,200]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'selectkbest__k':[50,55,60],'randomforestclassifier__n_estimators':[300,400,500]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(digit_pipeline, param_grid = params, cv=5, n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TARUN\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:115: UserWarning: Features [ 0 32 39 56] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\TARUN\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                                       ('selectkbest', SelectKBest()),\n",
       "                                       ('randomforestclassifier',\n",
       "                                        RandomForestClassifier())]),\n",
       "             n_jobs=4,\n",
       "             param_grid={'randomforestclassifier__n_estimators': [300, 400,\n",
       "                                                                  500],\n",
       "                         'selectkbest__k': [50, 55, 60]})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'randomforestclassifier__n_estimators': 400, 'selectkbest__k': 55}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9769902244251687"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_#before .9680 and now 97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.predict(testX[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('selectkbest', SelectKBest(k=55)),\n",
       "                ('randomforestclassifier',\n",
       "                 RandomForestClassifier(n_estimators=400))])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Tranformer for dealing with hetrogenous data\n",
    "* Regular pipeline intends to do same processing for all the columns \n",
    "* This doesn't work for hetrogenous data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<img scr='https://camo.githubusercontent.com/82ec7d9816d964e54f028d2ce5223ac529dd740e/68747470733a2f2f6769746875622e636f6d2f6564796f64612f446174612d536369656e746973742d70726f6772616d2f626c6f622f6d61737465722f41737369676e6d656e742f696d616765732f436f6c756d6e5472616e666f726d65722e706e673f7261773d74727565'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_data = pd.read_csv('https://raw.githubusercontent.com/edyoda/data-science-complete-tutorial/master/Data/HR_comma_sep.csv.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_data.rename(columns={'sales':'dept'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>time_spend_company</th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>left</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>dept</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>13761</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.60</td>\n",
       "      <td>4</td>\n",
       "      <td>258</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2460</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.72</td>\n",
       "      <td>4</td>\n",
       "      <td>167</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3370</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.83</td>\n",
       "      <td>3</td>\n",
       "      <td>188</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9932</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.89</td>\n",
       "      <td>5</td>\n",
       "      <td>261</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>marketing</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14746</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.56</td>\n",
       "      <td>2</td>\n",
       "      <td>156</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       satisfaction_level  last_evaluation  number_project  \\\n",
       "13761                0.63             0.60               4   \n",
       "2460                 0.86             0.72               4   \n",
       "3370                 0.64             0.83               3   \n",
       "9932                 0.17             0.89               5   \n",
       "14746                0.37             0.56               2   \n",
       "\n",
       "       average_montly_hours  time_spend_company  Work_accident  left  \\\n",
       "13761                   258                   3              0     0   \n",
       "2460                    167                   2              0     0   \n",
       "3370                    188                   4              0     0   \n",
       "9932                    261                   5              0     0   \n",
       "14746                   156                   3              0     1   \n",
       "\n",
       "       promotion_last_5years       dept  salary  \n",
       "13761                      0      sales  medium  \n",
       "2460                       0      sales     low  \n",
       "3370                       0      sales     low  \n",
       "9932                       0  marketing  medium  \n",
       "14746                      0      sales  medium  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_data = hr_data.drop(columns=['left'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_data = hr_data.left"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Different Columns needs different preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "satisfaction_level       float64\n",
       "last_evaluation          float64\n",
       "number_project             int64\n",
       "average_montly_hours       int64\n",
       "time_spend_company         int64\n",
       "Work_accident              int64\n",
       "promotion_last_5years      int64\n",
       "dept                      object\n",
       "salary                    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_data = feature_data.select_dtypes(include=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_data = feature_data.select_dtypes(include=['int'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_data = feature_data.select_dtypes(include=['float'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   satisfaction_level  last_evaluation\n",
       "0                0.38             0.53\n",
       "1                0.80             0.86\n",
       "2                0.11             0.88\n",
       "3                0.72             0.87"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_data[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <b>Float</b> satisfaction_level & last_evaluation don't need preprocessing\n",
    "* <b>Int</b> number_project,average_montly_hours,time_spend_company,Work_accident,promotion_last_5years need MinMaxScaler\n",
    "* <b>Object</b> dept & Salary need OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer # dealing with NaN values\n",
    "# SimplImputer is for handling missing data in pipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat_pipeline = make_pipeline(SimpleImputer(), OrdinalEncoder())\n",
    "cat_pipeline = make_pipeline(OrdinalEncoder())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_pipeline = make_pipeline(MinMaxScaler(), SelectKBest(k=3, score_func=f_classif))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = make_column_transformer(\n",
    "    (cat_pipeline,cat_data.columns),\n",
    "    (int_pipeline,int_data.columns),\n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(preprocessor, RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, testX, trainY, testY = train_test_split(feature_data, target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>time_spend_company</th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>dept</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10726</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.84</td>\n",
       "      <td>5</td>\n",
       "      <td>189</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>technical</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5403</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.81</td>\n",
       "      <td>3</td>\n",
       "      <td>166</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>IT</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       satisfaction_level  last_evaluation  number_project  \\\n",
       "10726                0.13             0.84               5   \n",
       "5403                 0.68             0.81               3   \n",
       "\n",
       "       average_montly_hours  time_spend_company  Work_accident  \\\n",
       "10726                   189                   5              0   \n",
       "5403                    166                   2              0   \n",
       "\n",
       "       promotion_last_5years       dept  salary  \n",
       "10726                      0  technical     low  \n",
       "5403                       0         IT  medium  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('pipeline-1',\n",
       "                                                  Pipeline(steps=[('ordinalencoder',\n",
       "                                                                   OrdinalEncoder())]),\n",
       "                                                  Index(['dept', 'salary'], dtype='object')),\n",
       "                                                 ('pipeline-2',\n",
       "                                                  Pipeline(steps=[('minmaxscaler',\n",
       "                                                                   MinMaxScaler()),\n",
       "                                                                  ('selectkbest',\n",
       "                                                                   SelectKBest(k=3))]),\n",
       "                                                  Index([], dtype='object'))])),\n",
       "                ('randomforestclassifier', RandomForestClassifier())])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0], dtype=int64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict(testX[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9909333333333333"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.score(testX,testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pipeline-1',\n",
       "  Pipeline(steps=[('ordinalencoder', OrdinalEncoder())]),\n",
       "  Index(['dept', 'salary'], dtype='object')),\n",
       " ('pipeline-2', Pipeline(steps=[('minmaxscaler', MinMaxScaler()),\n",
       "                  ('selectkbest', SelectKBest(k=3))]), Index([], dtype='object'))]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.steps[0][1].transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'columntransformer__pipeline-2__selectkbest__k':[2,3,4,5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(pipeline, param_grid=params, n_jobs=4, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('columntransformer',\n",
       "                                        ColumnTransformer(remainder='passthrough',\n",
       "                                                          transformers=[('pipeline-1',\n",
       "                                                                         Pipeline(steps=[('ordinalencoder',\n",
       "                                                                                          OrdinalEncoder())]),\n",
       "                                                                         Index(['dept', 'salary'], dtype='object')),\n",
       "                                                                        ('pipeline-2',\n",
       "                                                                         Pipeline(steps=[('minmaxscaler',\n",
       "                                                                                          MinMaxScaler()),\n",
       "                                                                                         ('selectkbest',\n",
       "                                                                                          SelectKBest(k=3))]),\n",
       "                                                                         Index([], dtype='object'))])),\n",
       "                                       ('randomforestclassifier',\n",
       "                                        RandomForestClassifier())]),\n",
       "             n_jobs=4,\n",
       "             param_grid={'columntransformer__pipeline-2__selectkbest__k': [2, 3,\n",
       "                                                                           4,\n",
       "                                                                           5]})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(trainX,trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'columntransformer__pipeline-2__selectkbest__k': 4}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9911100834938985"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disadvantages of Pipeline\n",
    "* Doesn't support Online Learning\n",
    "\n",
    "\n",
    "### Dealing with imbalanced data in pipeline\n",
    "* Use imblearn make_pipeline rather than scikit makepipeline as RandomOverSampler is not supported in Scikit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    11428\n",
       "1     3571\n",
       "Name: left, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_data.value_counts() #data is not balanced "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TARUN\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\TARUN\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.ensemble.bagging module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\TARUN\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.ensemble.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\TARUN\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\TARUN\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\TARUN\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This make_pipeline is not scikit pipeline but imblearn which support Oversampler as part of pipeline\n",
    "pipeline = make_pipeline (preprocessor, RandomOverSampler(),RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TARUN\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:86: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('pipeline-1',\n",
       "                                                  Pipeline(steps=[('ordinalencoder',\n",
       "                                                                   OrdinalEncoder())]),\n",
       "                                                  Index(['dept', 'salary'], dtype='object')),\n",
       "                                                 ('pipeline-2',\n",
       "                                                  Pipeline(steps=[('minmaxscaler',\n",
       "                                                                   MinMaxScaler()),\n",
       "                                                                  ('selectkbest',\n",
       "                                                                   SelectKBest(k=3))]),\n",
       "                                                  Index([], dtype='object'))])),\n",
       "                ('randomoversampler', RandomOverSampler()),\n",
       "                ('randomforestclassifier', RandomForestClassifier())])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(trainX,trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9906666666666667"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.score(testX,testY)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
